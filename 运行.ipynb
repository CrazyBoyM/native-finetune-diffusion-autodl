{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373c292b-28d5-4607-a253-244d84c0bf21",
   "metadata": {},
   "source": [
    "# Native Finetune Diffusion 集成训练环境\n",
    "一种更native的stable diffusion模型finetune方式 (改进于原始的dreambooth)\n",
    "\n",
    "本环境是对日本大佬@Kohya S方法的在线运行封装\n",
    "https://note.com/kohya_ss/n/nbf7ce8d80f29  \n",
    "\n",
    "主要包含以下特性：\n",
    "- 支持finetune unet\n",
    "- 支持finetune text encoder\n",
    "- 支持更长的clip token输入长度限制（75， 150， 225）\n",
    "- 支持采用clip倒数第二层的输出（以更接近NovelAI的训练技巧）\n",
    "- 支持使用非固定分辨率训练，以保留更多图像信息（无需先裁剪数据集为512x512）\n",
    "- 支持图像的自动标注（prompt / tags）\n",
    "- 支持训练Stable diffusion 2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b8fe-f9e8-4151-9de6-88cee1440262",
   "metadata": {},
   "source": [
    "## 前置环境处理\n",
    "把缓存文件归位(节省后面下载的时间)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fbc4b-6aea-4e2a-abab-85b3eaa84955",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /root/.cache\n",
    "!mv /root/models-cache /root/.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93104244-500c-4743-93ca-b9183d8dd5fc",
   "metadata": {},
   "source": [
    "## 进行数据标注\n",
    "\n",
    "这里推荐手动标注数据（对于AI难以进行自动标注的数据，比如工业零件、纹身、图案、水墨画、国风等），或使用下面的脚本工具创建自动标注。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7324-f4df-4847-91f6-2033004086fe",
   "metadata": {},
   "source": [
    "### 一、针对真实图像数据（生成自然描述）\n",
    "生成自然语言描述，速度相对比较慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967de1c-b29f-47d0-8d42-7548df424d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/label_images_with_caption.py ./datasets/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3567e6-cbc7-48fc-8c91-7e302390f672",
   "metadata": {},
   "source": [
    "合并caption到json列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18969d-0aa2-4345-ada1-c4eb38f7ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_captions_to_metadata.py \\\n",
    "        ./datasets/test \\\n",
    "        meta_cap.json # 输出的tags标注列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b45e8-2df3-437c-860c-fced7b607d53",
   "metadata": {},
   "source": [
    "### 二、针对二次元数据（生成danbooru tags）\n",
    "生成由大量标签组成的描述(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea445a-34f3-4707-9678-aab51eb7fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/label_images_with_tags.py \\\n",
    "        --path ./datasets/test \\\n",
    "        --threshold 0.75 # 阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908bbc9d-fb9a-4bfa-8d31-ff844a4709b3",
   "metadata": {},
   "source": [
    "合并tags标签到json\n",
    "\n",
    "这里也可通过指定--in_json meta_cap.json把上面带有caption的标注放进来，追加tags标记，训练时将会同时读取caption和tags一块进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c9978-b6c5-496c-a0d2-b6bd6cf63565",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_dd_tags_to_metadata.py \\\n",
    "        ./datasets/test \\\n",
    "        --in_json meta_cap.json \\\n",
    "        meta_cap_dd.json # 输出的tags标注列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba080ac-501b-4591-b4e7-2fd697b3091d",
   "metadata": {},
   "source": [
    "### 三、清洗标注列表\n",
    "- 如果只进行了自然描述的标注生成，请把下方meta_cap_dd.json改为meta_cap.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83c75b-49f6-415d-bb5f-2dbf606fdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python clean_captions_and_tags.py \\\n",
    "        ./datasets/test \\\n",
    "        --in_json meta_cap_dd.json \\\n",
    "        --out_json meta_clean.json # 清洗后输出的标注列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae95cb-c9c4-4111-9b27-dd0200026902",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 预处理训练样本为隐变量\n",
    "- --max_resolution默认512,512\n",
    "- 如训练sd二代模型，请添加 --v2  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6729300-0c71-4e19-9b49-bdfe3b445290",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prepare_buckets_latents.py \\\n",
    "    ./datasets/test  \\\n",
    "    meta_clean.json \\\n",
    "    meta_lat.json \\\n",
    "    --batch_size 4 \\\n",
    "    --mixed_precision fp16 \\\n",
    "    --max_resolution 768,768 \\\n",
    "    ./models/novel_lastest.ckpt # 待训练的基础模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c672d1e-34d4-401a-97b0-816da6587f8e",
   "metadata": {},
   "source": [
    "## Native Finetune 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec605d3-31f7-423b-a4da-5fe169d22de2",
   "metadata": {},
   "source": [
    "### 训练SD 1代模型：\n",
    "- --pretrained_model_name_or_path 基底模型路径  \n",
    "- --train_data_dir 数据集路径  \n",
    "- --save_precision=fp16 以半精度保存权重\n",
    "- --save_every_n_epochs 每训练多少个epoch保存一次ckpt检查点（注意磁盘空间容量，如果满了会导致训练失败）\n",
    "- --max_token_length 225、115、75可选\n",
    "- --clip_skip=2 使用clip倒数第二层的输出来进行训练，更接近NovelAI的方式（需要使用时在webui同样设置clip_skip=2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da569bec-4290-46f0-adeb-e3b61d25a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /root/tf-logs/*\n",
    "!accelerate launch --num_cpu_threads_per_process 8 fine_tune.py \\\n",
    "    --pretrained_model_name_or_path=./models/novel_lastest.ckpt \\\n",
    "    --in_json meta_lat.json \\\n",
    "    --train_data_dir=./datasets/test \\\n",
    "    --output_dir=./fine_tuned \\\n",
    "    --shuffle_caption \\\n",
    "    --logging_dir=\"/root/tf-logs\" \\\n",
    "    --train_batch_size=1 --learning_rate=5e-6 --max_train_steps=10000 \\\n",
    "    --use_8bit_adam --xformers --gradient_checkpointing \\\n",
    "    --mixed_precision=fp16 \\\n",
    "    --max_token_length=225 \\\n",
    "    --clip_skip=2 \\\n",
    "    --save_every_n_epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbdfdc-57f6-493f-a3b2-e6b7d824b57b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 训练SD二代模型\n",
    "\n",
    "- 训练768x768模型时，需要指定--v_parameterization (512x512的Stable diffusion-base2.0模型不需要) \n",
    "\n",
    "769-v-ema.ckpt可通过以下命令下载：  \n",
    "wget https://huggingface.co/stabilityai/stable-diffusion-2/resolve/main/768-v-ema.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c43b7b-abe5-408f-9928-94b45c634d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /root/tf-logs/*\n",
    "!accelerate launch --num_cpu_threads_per_process 8 fine_tune.py \\\n",
    "    --pretrained_model_name_or_path=./models/768-v-ema.ckpt \\\n",
    "    --in_json meta_lat.json \\\n",
    "    --train_data_dir=./datasets/test \\\n",
    "    --output_dir=./fine_tuned \\\n",
    "    --shuffle_caption \\\n",
    "    --logging_dir=\"/root/tf-logs\" \\\n",
    "    --train_batch_size=1 --learning_rate=5e-6 --max_train_steps=10000 \\\n",
    "    --use_8bit_adam --xformers --gradient_checkpointing \\\n",
    "    --mixed_precision=fp16 \\\n",
    "    --save_precision=fp16 \\\n",
    "    --save_every_n_epochs=100 \\\n",
    "    --v2 \\\n",
    "    --v_parameterization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736dabbf-2f9b-4879-aedd-fdf9d5ee50dc",
   "metadata": {},
   "source": [
    "具体说明可以查看原作者的教程（日文）：  \n",
    "https://note.com/kohya_ss/n/nbf7ce8d80f29\n",
    "\n",
    "对应视频教程可在主页查找，https://space.bilibili.com/291593914"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc86d2-2184-41f9-badf-0c3feafbb8ca",
   "metadata": {},
   "source": [
    "如果感兴趣，可以加XDiffusion交流群 455521885 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0177f-0313-47be-863a-34f23799ef5d",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dad450-0bf4-4353-b1b6-c3a50ad9e469",
   "metadata": {},
   "source": [
    "为了方便使用，避免频繁在多个代码间切换的麻烦，在tools目录里也集成了多个自己常用的工具脚本，涵盖模型融合、图像批处理、原始dreambooth、Textual inversion、prune、上传cos等，可自行研究取用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002a96a-8dff-4982-a833-c1d68405420e",
   "metadata": {},
   "source": [
    "如：模型融合\n",
    "```\n",
    "!python tools/ckpt_merge.py A.ckpt B.ckpt --alpha 0.3 --without_vae\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b306d-f674-4ff7-9ef4-3abb4ffa6ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
